{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede85139",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import re, json, csv, numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import torch, sacrebleu\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from bert_score import score as bertscore\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import os, re, json, random, csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch, sacrebleu\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    ")\n",
    "from peft import PeftModel\n",
    "from bert_score import score as bertscore\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28207c25",
   "metadata": {},
   "source": [
    "## Logging to Hugging Face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304864a-1393-4bbf-85ea-1c7621338e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "login(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44c63d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124e572-2c56-49b6-88a6-f33f57a99a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"  \n",
    "OUT_DIR  = Path(\"eval_external_llama31_8b\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PRED_DIR = OUT_DIR / \"preds\"; PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEST_PATH = Path(\"data_splits/test.jsonl\")\n",
    "GEN_KW = dict(max_new_tokens=256, do_sample=True, top_p=0.95, top_k=50, temperature=0.6)\n",
    "USE_4BIT = False \n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fc9f8",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef490d-a74b-490d-bfa1-59e2c296beae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED); np.random.seed(SEED); \n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def read_jsonl(p):\n",
    "    rows=[]\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip(): rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "test_rows = read_jsonl(TEST_PATH)\n",
    "len(test_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b1f90",
   "metadata": {},
   "source": [
    "## Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd51d0c-7bf2-42a9-9c71-065ca49623e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:08<00:00,  2.23s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n",
      "Generating: Llama-3.1-8B-Instruct:   0%|          | 0/836 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   0%|          | 1/836 [00:08<2:02:28,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   0%|          | 2/836 [00:15<1:43:09,  7.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   0%|          | 3/836 [00:20<1:26:35,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   0%|          | 4/836 [00:26<1:27:43,  6.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 5/836 [00:30<1:13:28,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 6/836 [00:33<1:06:11,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 7/836 [00:40<1:14:16,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 8/836 [00:41<53:10,  3.85s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 9/836 [00:47<1:04:10,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|          | 10/836 [00:47<46:07,  3.35s/it] Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|▏         | 11/836 [00:54<59:55,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   1%|▏         | 12/836 [01:00<1:07:35,  4.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 13/836 [01:07<1:13:27,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 14/836 [01:09<1:01:34,  4.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 15/836 [01:16<1:10:40,  5.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 16/836 [01:22<1:14:29,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 17/836 [01:28<1:16:48,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 18/836 [01:34<1:18:40,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 19/836 [01:37<1:05:36,  4.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   2%|▏         | 20/836 [01:40<57:58,  4.26s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 21/836 [01:41<47:52,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 22/836 [01:48<58:49,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 23/836 [01:48<44:35,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 24/836 [01:55<56:23,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 25/836 [02:01<1:04:42,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 26/836 [02:07<1:10:43,  5.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 27/836 [02:08<52:50,  3.92s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 28/836 [02:14<1:01:48,  4.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   3%|▎         | 29/836 [02:15<44:33,  3.31s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▎         | 30/836 [02:15<33:06,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▎         | 31/836 [02:21<48:09,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 32/836 [02:22<37:25,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 33/836 [02:25<36:58,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 34/836 [02:29<43:13,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 35/836 [02:35<54:56,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 36/836 [02:42<1:03:33,  4.77s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   4%|▍         | 37/836 [02:44<52:17,  3.93s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▍         | 38/836 [02:50<1:01:22,  4.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▍         | 39/836 [02:51<48:18,  3.64s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▍         | 40/836 [02:56<51:28,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▍         | 41/836 [02:57<40:42,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▌         | 42/836 [02:58<31:05,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▌         | 43/836 [03:00<29:48,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▌         | 44/836 [03:06<44:51,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   5%|▌         | 45/836 [03:07<36:06,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 46/836 [03:13<49:10,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 47/836 [03:15<43:14,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 48/836 [03:17<38:10,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 49/836 [03:23<50:39,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 50/836 [03:27<48:47,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 51/836 [03:30<49:13,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▌         | 52/836 [03:37<58:27,  4.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▋         | 53/836 [03:41<58:01,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   6%|▋         | 54/836 [03:43<48:09,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 55/836 [03:49<57:21,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 56/836 [03:55<1:03:53,  4.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 57/836 [03:59<59:20,  4.57s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 58/836 [04:05<1:04:41,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 59/836 [04:07<54:09,  4.18s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 60/836 [04:13<1:01:10,  4.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 61/836 [04:19<1:06:10,  5.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   7%|▋         | 62/836 [04:25<1:10:25,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 63/836 [04:32<1:13:44,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 64/836 [04:38<1:16:21,  5.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 65/836 [04:45<1:18:34,  6.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 66/836 [04:52<1:22:57,  6.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 67/836 [04:59<1:24:11,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 68/836 [05:05<1:22:31,  6.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 69/836 [05:06<1:01:15,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 70/836 [05:12<1:06:21,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   8%|▊         | 71/836 [05:18<1:10:03,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▊         | 72/836 [05:19<50:58,  4.00s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▊         | 73/836 [05:25<58:53,  4.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 74/836 [05:31<1:04:36,  5.09s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 75/836 [05:37<1:08:03,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 76/836 [05:43<1:10:52,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 77/836 [05:44<52:47,  4.17s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 78/836 [05:47<49:59,  3.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:   9%|▉         | 79/836 [05:54<59:10,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|▉         | 80/836 [06:00<1:05:20,  5.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|▉         | 81/836 [06:01<48:29,  3.85s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|▉         | 82/836 [06:05<48:18,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|▉         | 83/836 [06:06<36:39,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|█         | 84/836 [06:12<49:19,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|█         | 85/836 [06:15<46:50,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|█         | 86/836 [06:21<56:17,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  10%|█         | 87/836 [06:28<1:02:35,  5.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 88/836 [06:34<1:07:18,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 89/836 [06:38<1:02:01,  4.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 90/836 [06:42<56:53,  4.58s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 91/836 [06:42<41:32,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 92/836 [06:48<52:44,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 93/836 [06:52<49:11,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█         | 94/836 [06:57<54:53,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█▏        | 95/836 [07:01<52:36,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  11%|█▏        | 96/836 [07:08<1:00:36,  4.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 97/836 [07:14<1:05:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 98/836 [07:17<58:43,  4.77s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 99/836 [07:24<1:05:06,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 100/836 [07:30<1:07:42,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 101/836 [07:33<1:00:12,  4.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 102/836 [07:40<1:06:00,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 103/836 [07:45<1:04:26,  5.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  12%|█▏        | 104/836 [07:46<48:22,  3.97s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 105/836 [07:51<51:58,  4.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 106/836 [07:56<55:02,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 107/836 [08:01<57:19,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 108/836 [08:07<1:02:24,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 109/836 [08:09<50:45,  4.19s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 110/836 [08:10<37:29,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 111/836 [08:16<48:25,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  13%|█▎        | 112/836 [08:17<38:21,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▎        | 113/836 [08:23<48:56,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▎        | 114/836 [08:29<56:26,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 115/836 [08:34<54:41,  4.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 116/836 [08:38<53:08,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 117/836 [08:44<59:20,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 118/836 [08:50<1:03:09,  5.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 119/836 [08:56<1:05:43,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 120/836 [09:02<1:07:20,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  14%|█▍        | 121/836 [09:04<53:20,  4.48s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▍        | 122/836 [09:08<53:52,  4.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▍        | 123/836 [09:10<43:43,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▍        | 124/836 [09:16<51:58,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▍        | 125/836 [09:18<43:46,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▌        | 126/836 [09:24<52:30,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▌        | 127/836 [09:27<46:45,  3.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▌        | 128/836 [09:27<33:06,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  15%|█▌        | 129/836 [09:28<23:59,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 130/836 [09:34<38:08,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 131/836 [09:34<29:13,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 132/836 [09:35<23:19,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 133/836 [09:40<32:53,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 134/836 [09:41<27:36,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▌        | 135/836 [09:45<34:07,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▋        | 136/836 [09:47<28:12,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  16%|█▋        | 137/836 [09:47<21:12,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 138/836 [09:48<18:39,  1.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 139/836 [09:50<20:07,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 140/836 [09:52<20:49,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 141/836 [09:58<35:47,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 142/836 [09:59<28:39,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 143/836 [10:05<41:34,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 144/836 [10:09<41:24,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 145/836 [10:13<43:19,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  17%|█▋        | 146/836 [10:19<51:15,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 147/836 [10:25<56:44,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 148/836 [10:26<41:02,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 149/836 [10:29<39:09,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 150/836 [10:29<28:46,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 151/836 [10:30<21:30,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 152/836 [10:32<21:49,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 153/836 [10:36<30:07,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  18%|█▊        | 154/836 [10:37<25:06,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▊        | 155/836 [10:38<19:56,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▊        | 156/836 [10:40<21:36,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 157/836 [10:41<18:35,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 158/836 [10:47<33:32,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 159/836 [10:53<43:48,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 160/836 [10:55<37:56,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 161/836 [10:56<28:58,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 162/836 [11:02<40:28,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  19%|█▉        | 163/836 [11:03<30:40,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|█▉        | 164/836 [11:05<27:10,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|█▉        | 165/836 [11:05<20:39,  1.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|█▉        | 166/836 [11:10<30:31,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|█▉        | 167/836 [11:14<35:21,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|██        | 168/836 [11:19<40:08,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|██        | 169/836 [11:19<30:06,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|██        | 170/836 [11:21<25:15,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  20%|██        | 171/836 [11:24<29:49,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 172/836 [11:30<41:11,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 173/836 [11:32<33:34,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 174/836 [11:38<44:08,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 175/836 [11:43<47:44,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 176/836 [11:49<53:14,  4.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██        | 177/836 [11:53<48:21,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██▏       | 178/836 [11:59<53:36,  4.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  21%|██▏       | 179/836 [12:00<41:01,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 180/836 [12:06<48:40,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 181/836 [12:07<37:22,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 182/836 [12:12<42:58,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 183/836 [12:15<39:16,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 184/836 [12:16<31:22,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 185/836 [12:22<41:37,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 186/836 [12:25<37:37,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 187/836 [12:31<45:51,  4.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  22%|██▏       | 188/836 [12:37<51:41,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 189/836 [12:37<37:54,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 190/836 [12:40<36:30,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 191/836 [12:46<45:01,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 192/836 [12:48<36:13,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 193/836 [12:54<44:47,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 194/836 [12:57<40:55,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 195/836 [13:00<36:55,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  23%|██▎       | 196/836 [13:06<45:25,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▎       | 197/836 [13:12<51:01,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▎       | 198/836 [13:18<55:04,  5.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 199/836 [13:24<57:43,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 200/836 [13:30<59:44,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 201/836 [13:36<1:01:01,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 202/836 [13:42<1:01:59,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 203/836 [13:47<59:12,  5.61s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  24%|██▍       | 204/836 [13:53<1:00:54,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▍       | 205/836 [13:56<51:33,  4.90s/it]  Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▍       | 206/836 [14:02<55:18,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▍       | 207/836 [14:03<40:13,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▍       | 208/836 [14:03<29:51,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▌       | 209/836 [14:05<26:01,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▌       | 210/836 [14:10<34:46,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▌       | 211/836 [14:12<29:46,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▌       | 212/836 [14:18<39:44,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  25%|██▌       | 213/836 [14:24<47:20,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 214/836 [14:25<35:23,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 215/836 [14:27<30:58,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 216/836 [14:31<32:32,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 217/836 [14:37<42:43,  4.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 218/836 [14:39<36:05,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▌       | 219/836 [14:43<37:43,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▋       | 220/836 [14:50<46:06,  4.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  26%|██▋       | 221/836 [14:50<33:17,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 222/836 [14:53<31:47,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 223/836 [14:54<26:23,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 224/836 [14:55<19:57,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 225/836 [15:01<33:25,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 226/836 [15:01<24:36,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 227/836 [15:02<18:32,  1.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 228/836 [15:04<19:46,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  27%|██▋       | 229/836 [15:10<32:40,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 230/836 [15:17<41:55,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 231/836 [15:18<33:46,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 232/836 [15:22<37:07,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 233/836 [15:27<39:50,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 234/836 [15:33<45:59,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 235/836 [15:36<40:38,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 236/836 [15:42<46:26,  4.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 237/836 [15:48<50:53,  5.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  28%|██▊       | 238/836 [15:49<39:41,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▊       | 239/836 [15:56<46:23,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▊       | 240/836 [16:02<50:39,  5.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 241/836 [16:05<44:28,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 242/836 [16:06<35:15,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 243/836 [16:07<27:40,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 244/836 [16:08<21:38,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 245/836 [16:09<18:28,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  29%|██▉       | 246/836 [16:15<30:59,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|██▉       | 247/836 [16:16<24:41,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|██▉       | 248/836 [16:18<22:38,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|██▉       | 249/836 [16:18<16:16,  1.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|██▉       | 250/836 [16:25<29:53,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|███       | 251/836 [16:31<39:25,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|███       | 252/836 [16:37<45:20,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|███       | 253/836 [16:43<49:32,  5.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  30%|███       | 254/836 [16:44<37:41,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 255/836 [16:50<44:15,  4.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 256/836 [16:52<36:13,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 257/836 [16:53<28:21,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 258/836 [16:57<31:28,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 259/836 [17:04<39:54,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 260/836 [17:10<45:36,  4.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███       | 261/836 [17:12<36:57,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███▏      | 262/836 [17:14<32:48,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  31%|███▏      | 263/836 [17:20<40:36,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 264/836 [17:23<36:50,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 265/836 [17:29<42:47,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 266/836 [17:35<47:02,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 267/836 [17:41<49:59,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 268/836 [17:47<52:09,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 269/836 [17:53<52:37,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 270/836 [17:57<49:36,  5.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  32%|███▏      | 271/836 [17:58<36:04,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 272/836 [18:04<42:02,  4.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 273/836 [18:05<33:10,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 274/836 [18:07<27:08,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 275/836 [18:13<35:54,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 276/836 [18:16<34:30,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 277/836 [18:18<30:28,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 278/836 [18:19<22:16,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 279/836 [18:19<17:50,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  33%|███▎      | 280/836 [18:21<17:07,  1.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▎      | 281/836 [18:27<28:43,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▎      | 282/836 [18:33<36:49,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 283/836 [18:34<28:12,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 284/836 [18:39<32:54,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 285/836 [18:39<24:18,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 286/836 [18:43<25:40,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 287/836 [18:49<35:57,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  34%|███▍      | 288/836 [18:56<42:41,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▍      | 289/836 [18:57<34:38,  3.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▍      | 290/836 [19:04<41:31,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▍      | 291/836 [19:10<46:38,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▍      | 292/836 [19:12<37:54,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▌      | 293/836 [19:19<44:00,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▌      | 294/836 [19:20<33:51,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▌      | 295/836 [19:20<25:03,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  35%|███▌      | 296/836 [19:26<34:01,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 297/836 [19:32<39:34,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 298/836 [19:33<29:35,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 299/836 [19:39<36:00,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 300/836 [19:40<29:41,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 301/836 [19:46<37:18,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 302/836 [19:51<38:19,  4.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▌      | 303/836 [19:56<41:02,  4.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▋      | 304/836 [19:58<32:02,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  36%|███▋      | 305/836 [19:59<26:05,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 306/836 [20:01<24:08,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 307/836 [20:08<34:29,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 308/836 [20:11<31:09,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 309/836 [20:17<39:18,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 310/836 [20:24<44:52,  5.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 311/836 [20:27<38:40,  4.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 312/836 [20:33<44:31,  5.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  37%|███▋      | 313/836 [20:35<34:55,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 314/836 [20:41<41:24,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 315/836 [20:44<35:58,  4.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 316/836 [20:49<37:05,  4.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 317/836 [20:55<42:46,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 318/836 [20:58<36:14,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 319/836 [20:58<26:45,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 320/836 [21:04<34:37,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  38%|███▊      | 321/836 [21:10<39:48,  4.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▊      | 322/836 [21:13<33:11,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▊      | 323/836 [21:16<33:03,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 324/836 [21:17<25:05,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 325/836 [21:23<33:05,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 326/836 [21:24<25:06,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 327/836 [21:30<32:50,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 328/836 [21:36<38:10,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 329/836 [21:42<42:17,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  39%|███▉      | 330/836 [21:42<30:17,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|███▉      | 331/836 [21:49<36:28,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|███▉      | 332/836 [21:50<30:19,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|███▉      | 333/836 [21:53<27:48,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|███▉      | 334/836 [21:54<21:25,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|████      | 335/836 [22:00<30:12,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|████      | 336/836 [22:00<22:05,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|████      | 337/836 [22:01<17:05,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  40%|████      | 338/836 [22:02<14:23,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 339/836 [22:08<25:14,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 340/836 [22:09<19:02,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 341/836 [22:10<16:10,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 342/836 [22:10<11:58,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 343/836 [22:16<23:24,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████      | 344/836 [22:17<17:55,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████▏     | 345/836 [22:17<13:52,  1.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  41%|████▏     | 346/836 [22:18<11:05,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 347/836 [22:24<22:37,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 348/836 [22:24<16:34,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 349/836 [22:25<13:55,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 350/836 [22:28<15:08,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 351/836 [22:34<25:22,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 352/836 [22:40<32:25,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 353/836 [22:41<26:00,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 354/836 [22:47<32:55,  4.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  42%|████▏     | 355/836 [22:53<37:48,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 356/836 [22:55<30:39,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 357/836 [22:57<24:58,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 358/836 [23:00<26:13,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 359/836 [23:06<32:49,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 360/836 [23:07<24:34,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 361/836 [23:10<24:32,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 362/836 [23:12<21:45,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  43%|████▎     | 363/836 [23:14<18:16,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▎     | 364/836 [23:16<17:43,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▎     | 365/836 [23:17<16:26,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 366/836 [23:18<13:51,  1.77s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 367/836 [23:19<10:55,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 368/836 [23:25<22:30,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 369/836 [23:26<18:37,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 370/836 [23:28<15:43,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 371/836 [23:29<14:02,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  44%|████▍     | 372/836 [23:30<12:51,  1.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▍     | 373/836 [23:36<22:56,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▍     | 374/836 [23:42<29:54,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▍     | 375/836 [23:48<34:44,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▍     | 376/836 [23:54<38:07,  4.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▌     | 377/836 [24:00<40:25,  5.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▌     | 378/836 [24:03<34:58,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▌     | 379/836 [24:09<38:19,  5.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  45%|████▌     | 380/836 [24:14<36:59,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 381/836 [24:20<39:40,  5.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 382/836 [24:20<28:22,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 383/836 [24:26<33:38,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 384/836 [24:32<37:13,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 385/836 [24:38<39:41,  5.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▌     | 386/836 [24:39<28:31,  3.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▋     | 387/836 [24:45<33:46,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  46%|████▋     | 388/836 [24:52<38:20,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 389/836 [24:56<36:42,  4.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 390/836 [25:00<34:35,  4.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 391/836 [25:06<37:36,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 392/836 [25:07<28:41,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 393/836 [25:10<27:19,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 394/836 [25:12<22:21,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 395/836 [25:13<17:16,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 396/836 [25:13<13:14,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  47%|████▋     | 397/836 [25:14<10:45,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 398/836 [25:20<20:55,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 399/836 [25:26<28:20,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 400/836 [25:28<22:24,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 401/836 [25:30<19:55,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 402/836 [25:36<28:01,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 403/836 [25:43<33:41,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 404/836 [25:49<37:43,  5.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  48%|████▊     | 405/836 [25:56<40:29,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▊     | 406/836 [25:58<33:52,  4.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▊     | 407/836 [26:05<37:11,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 408/836 [26:05<26:59,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 409/836 [26:11<32:01,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 410/836 [26:17<35:21,  4.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 411/836 [26:18<25:40,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 412/836 [26:24<31:05,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  49%|████▉     | 413/836 [26:25<23:50,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|████▉     | 414/836 [26:32<31:12,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|████▉     | 415/836 [26:39<35:51,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|████▉     | 416/836 [26:45<38:55,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|████▉     | 417/836 [26:52<40:26,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|█████     | 418/836 [26:58<41:12,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|█████     | 419/836 [27:04<41:33,  5.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|█████     | 420/836 [27:06<33:00,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|█████     | 421/836 [27:07<24:52,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  50%|█████     | 422/836 [27:09<21:29,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 423/836 [27:14<26:56,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 424/836 [27:17<23:17,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 425/836 [27:23<29:23,  4.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 426/836 [27:24<22:33,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 427/836 [27:28<23:28,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████     | 428/836 [27:34<29:24,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████▏    | 429/836 [27:36<23:42,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  51%|█████▏    | 430/836 [27:43<30:46,  4.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 431/836 [27:47<29:14,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 432/836 [27:53<32:37,  4.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 433/836 [27:53<23:45,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 434/836 [27:56<22:11,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 435/836 [28:02<27:46,  4.16s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 436/836 [28:08<31:52,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 437/836 [28:14<34:36,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  52%|█████▏    | 438/836 [28:18<31:50,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 439/836 [28:22<30:29,  4.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 440/836 [28:29<33:50,  5.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 441/836 [28:33<31:04,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 442/836 [28:39<33:49,  5.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 443/836 [28:45<35:25,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 444/836 [28:51<36:39,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 445/836 [28:57<37:48,  5.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 446/836 [29:04<40:12,  6.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  53%|█████▎    | 447/836 [29:10<40:23,  6.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▎    | 448/836 [29:11<30:06,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▎    | 449/836 [29:12<22:20,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 450/836 [29:18<27:29,  4.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 451/836 [29:20<22:05,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 452/836 [29:25<26:13,  4.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 453/836 [29:31<29:04,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 454/836 [29:32<21:18,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  54%|█████▍    | 455/836 [29:36<22:48,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▍    | 456/836 [29:41<25:36,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▍    | 457/836 [29:48<30:40,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▍    | 458/836 [29:53<31:38,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▍    | 459/836 [29:54<24:10,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▌    | 460/836 [30:00<28:13,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▌    | 461/836 [30:01<21:27,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▌    | 462/836 [30:07<26:17,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  55%|█████▌    | 463/836 [30:13<29:35,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 464/836 [30:19<32:02,  5.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 465/836 [30:25<32:33,  5.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 466/836 [30:31<33:59,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 467/836 [30:37<34:22,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 468/836 [30:37<24:59,  4.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 469/836 [30:43<28:32,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▌    | 470/836 [30:44<21:28,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▋    | 471/836 [30:45<17:10,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  56%|█████▋    | 472/836 [30:46<13:33,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 473/836 [30:47<11:15,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 474/836 [30:48<09:27,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 475/836 [30:49<08:30,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 476/836 [30:52<11:13,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 477/836 [30:58<18:46,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 478/836 [31:00<16:27,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 479/836 [31:01<14:07,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  57%|█████▋    | 480/836 [31:02<10:12,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 481/836 [31:02<07:55,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 482/836 [31:03<06:33,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 483/836 [31:04<06:14,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 484/836 [31:10<14:56,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 485/836 [31:10<11:15,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 486/836 [31:16<18:38,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 487/836 [31:23<24:09,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 488/836 [31:29<28:08,  4.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  58%|█████▊    | 489/836 [31:31<22:58,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▊    | 490/836 [31:32<18:08,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▊    | 491/836 [31:33<13:55,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 492/836 [31:34<11:54,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 493/836 [31:41<20:19,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 494/836 [31:48<25:24,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 495/836 [31:48<18:34,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 496/836 [31:55<24:57,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  59%|█████▉    | 497/836 [32:02<29:06,  5.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|█████▉    | 498/836 [32:06<27:09,  4.82s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|█████▉    | 499/836 [32:13<29:51,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|█████▉    | 500/836 [32:19<31:26,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|█████▉    | 501/836 [32:19<22:38,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|██████    | 502/836 [32:21<18:16,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|██████    | 503/836 [32:22<14:55,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|██████    | 504/836 [32:28<20:38,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  60%|██████    | 505/836 [32:30<17:47,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 506/836 [32:31<13:59,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 507/836 [32:32<10:12,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 508/836 [32:32<08:10,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 509/836 [32:39<15:54,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 510/836 [32:45<21:23,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 511/836 [32:51<25:02,  4.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████    | 512/836 [32:58<27:57,  5.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████▏   | 513/836 [33:04<29:20,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  61%|██████▏   | 514/836 [33:10<30:27,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 515/836 [33:11<23:03,  4.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 516/836 [33:12<16:54,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 517/836 [33:13<13:44,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 518/836 [33:13<10:38,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 519/836 [33:14<07:37,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 520/836 [33:14<06:19,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 521/836 [33:20<14:21,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  62%|██████▏   | 522/836 [33:21<11:31,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 523/836 [33:28<17:40,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 524/836 [33:34<21:57,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 525/836 [33:36<18:17,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 526/836 [33:37<14:36,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 527/836 [33:37<10:38,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 528/836 [33:41<13:38,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 529/836 [33:47<18:57,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  63%|██████▎   | 530/836 [33:54<22:58,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▎   | 531/836 [33:55<18:20,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▎   | 532/836 [33:59<18:28,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 533/836 [34:05<22:47,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 534/836 [34:07<18:21,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 535/836 [34:13<22:18,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 536/836 [34:19<23:21,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 537/836 [34:25<26:16,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 538/836 [34:32<28:04,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  64%|██████▍   | 539/836 [34:38<29:03,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▍   | 540/836 [34:44<29:30,  5.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▍   | 541/836 [34:51<29:58,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▍   | 542/836 [34:51<21:33,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▍   | 543/836 [34:58<25:35,  5.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▌   | 544/836 [35:00<19:32,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▌   | 545/836 [35:06<23:06,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▌   | 546/836 [35:07<17:04,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  65%|██████▌   | 547/836 [35:13<21:01,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 548/836 [35:19<22:26,  4.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 549/836 [35:21<19:00,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 550/836 [35:23<15:49,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 551/836 [35:25<14:10,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 552/836 [35:31<18:37,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▌   | 553/836 [35:33<16:23,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▋   | 554/836 [35:34<12:45,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  66%|██████▋   | 555/836 [35:36<10:42,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 556/836 [35:36<08:34,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 557/836 [35:37<06:54,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 558/836 [35:38<06:28,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 559/836 [35:45<13:30,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 560/836 [35:47<12:11,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 561/836 [35:53<17:07,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 562/836 [35:58<18:05,  3.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 563/836 [35:59<14:42,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  67%|██████▋   | 564/836 [36:01<12:29,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 565/836 [36:02<09:49,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 566/836 [36:08<15:03,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 567/836 [36:09<12:39,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 568/836 [36:15<16:09,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 569/836 [36:19<16:35,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 570/836 [36:19<11:49,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 571/836 [36:19<08:48,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  68%|██████▊   | 572/836 [36:25<14:20,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▊   | 573/836 [36:32<18:25,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▊   | 574/836 [36:38<20:55,  4.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 575/836 [36:39<15:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 576/836 [36:39<11:37,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 577/836 [36:42<11:22,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 578/836 [36:48<15:57,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 579/836 [36:49<11:56,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 580/836 [36:51<11:08,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  69%|██████▉   | 581/836 [36:53<10:29,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|██████▉   | 582/836 [36:58<13:16,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|██████▉   | 583/836 [37:04<17:04,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|██████▉   | 584/836 [37:10<19:44,  4.70s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|██████▉   | 585/836 [37:12<15:42,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|███████   | 586/836 [37:15<15:30,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|███████   | 587/836 [37:22<18:41,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|███████   | 588/836 [37:22<13:49,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  70%|███████   | 589/836 [37:23<10:08,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 590/836 [37:24<08:25,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 591/836 [37:25<07:49,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 592/836 [37:27<07:02,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 593/836 [37:30<08:33,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 594/836 [37:33<09:35,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████   | 595/836 [37:39<14:04,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████▏  | 596/836 [37:45<17:29,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  71%|███████▏  | 597/836 [37:52<19:52,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 598/836 [37:52<14:44,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 599/836 [37:59<18:16,  4.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 600/836 [38:06<20:26,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 601/836 [38:06<14:39,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 602/836 [38:12<17:29,  4.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 603/836 [38:18<19:11,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 604/836 [38:24<19:39,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 605/836 [38:27<17:03,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  72%|███████▏  | 606/836 [38:27<12:08,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 607/836 [38:27<08:55,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 608/836 [38:34<13:25,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 609/836 [38:34<09:51,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 610/836 [38:35<07:38,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 611/836 [38:35<05:34,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 612/836 [38:41<10:44,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 613/836 [38:47<13:46,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  73%|███████▎  | 614/836 [38:53<16:20,  4.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▎  | 615/836 [38:53<11:56,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▎  | 616/836 [38:54<09:05,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 617/836 [39:00<13:02,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 618/836 [39:06<15:45,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 619/836 [39:11<16:17,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 620/836 [39:12<12:03,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 621/836 [39:18<15:11,  4.24s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  74%|███████▍  | 622/836 [39:24<17:12,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▍  | 623/836 [39:31<18:49,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▍  | 624/836 [39:37<19:52,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▍  | 625/836 [39:38<14:21,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▍  | 626/836 [39:43<15:35,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▌  | 627/836 [39:49<17:24,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▌  | 628/836 [39:51<13:34,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▌  | 629/836 [39:56<15:03,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▌  | 630/836 [39:56<10:52,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  75%|███████▌  | 631/836 [39:59<09:52,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 632/836 [39:59<07:22,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 633/836 [40:05<11:31,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 634/836 [40:08<10:44,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 635/836 [40:14<13:40,  4.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 636/836 [40:15<10:40,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▌  | 637/836 [40:22<13:39,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▋  | 638/836 [40:28<15:39,  4.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  76%|███████▋  | 639/836 [40:29<12:20,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 640/836 [40:32<11:14,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 641/836 [40:34<10:07,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 642/836 [40:41<13:28,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 643/836 [40:48<15:57,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 644/836 [40:54<16:57,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 645/836 [40:55<12:39,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 646/836 [40:55<09:18,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  77%|███████▋  | 647/836 [41:01<12:15,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 648/836 [41:05<11:43,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 649/836 [41:10<13:15,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 650/836 [41:11<10:06,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 651/836 [41:17<12:47,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 652/836 [41:20<11:35,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 653/836 [41:23<10:57,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 654/836 [41:24<08:20,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 655/836 [41:27<08:27,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  78%|███████▊  | 656/836 [41:33<11:35,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▊  | 657/836 [41:40<13:42,  4.60s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▊  | 658/836 [41:41<10:27,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 659/836 [41:41<07:38,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 660/836 [41:42<05:35,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 661/836 [41:48<09:32,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 662/836 [41:53<10:35,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 663/836 [41:59<12:47,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  79%|███████▉  | 664/836 [42:05<14:18,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|███████▉  | 665/836 [42:11<15:22,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|███████▉  | 666/836 [42:18<16:06,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|███████▉  | 667/836 [42:18<11:33,  4.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|███████▉  | 668/836 [42:23<12:17,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|████████  | 669/836 [42:29<13:37,  4.89s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|████████  | 670/836 [42:35<14:31,  5.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|████████  | 671/836 [42:41<15:06,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  80%|████████  | 672/836 [42:43<11:37,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 673/836 [42:44<08:50,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 674/836 [42:50<11:08,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 675/836 [42:55<11:34,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 676/836 [42:57<09:32,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 677/836 [43:02<10:40,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 678/836 [43:02<07:57,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████  | 679/836 [43:03<06:28,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████▏ | 680/836 [43:09<08:32,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  81%|████████▏ | 681/836 [43:11<07:32,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 682/836 [43:14<07:31,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 683/836 [43:20<09:48,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 684/836 [43:26<11:44,  4.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 685/836 [43:27<09:06,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 686/836 [43:33<10:16,  4.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 687/836 [43:36<09:45,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 688/836 [43:37<07:32,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  82%|████████▏ | 689/836 [43:37<05:22,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 690/836 [43:38<04:22,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 691/836 [43:42<05:40,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 692/836 [43:44<05:41,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 693/836 [43:51<08:25,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 694/836 [43:53<07:27,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 695/836 [43:57<08:24,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 696/836 [43:59<07:13,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 697/836 [44:00<05:17,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  83%|████████▎ | 698/836 [44:01<04:19,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▎ | 699/836 [44:01<03:35,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▎ | 700/836 [44:08<06:35,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 701/836 [44:08<05:06,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 702/836 [44:09<04:07,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 703/836 [44:15<06:58,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 704/836 [44:18<06:24,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 705/836 [44:19<05:18,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  84%|████████▍ | 706/836 [44:20<04:31,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▍ | 707/836 [44:21<03:45,  1.74s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▍ | 708/836 [44:28<06:39,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▍ | 709/836 [44:29<05:18,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▍ | 710/836 [44:30<04:13,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▌ | 711/836 [44:31<03:39,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▌ | 712/836 [44:32<03:12,  1.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▌ | 713/836 [44:38<06:07,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  85%|████████▌ | 714/836 [44:40<05:35,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 715/836 [44:43<05:28,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 716/836 [44:46<05:43,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 717/836 [44:47<04:31,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 718/836 [44:48<03:37,  1.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 719/836 [44:54<06:05,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 720/836 [45:00<07:48,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▌ | 721/836 [45:04<07:37,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▋ | 722/836 [45:05<05:41,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  86%|████████▋ | 723/836 [45:06<04:25,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 724/836 [45:12<06:26,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 725/836 [45:13<05:10,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 726/836 [45:19<06:56,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 727/836 [45:25<08:07,  4.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 728/836 [45:31<08:59,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 729/836 [45:37<09:33,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 730/836 [45:44<09:56,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  87%|████████▋ | 731/836 [45:51<10:38,  6.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 732/836 [45:57<10:42,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 733/836 [45:59<08:10,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 734/836 [46:05<08:53,  5.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 735/836 [46:10<08:45,  5.21s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 736/836 [46:16<09:06,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 737/836 [46:22<09:23,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 738/836 [46:29<09:35,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  88%|████████▊ | 739/836 [46:35<09:41,  5.99s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▊ | 740/836 [46:40<09:05,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▊ | 741/836 [46:46<09:16,  5.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 742/836 [46:51<08:39,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 743/836 [46:54<07:32,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 744/836 [47:00<08:00,  5.23s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 745/836 [47:07<08:22,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 746/836 [47:10<07:09,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 747/836 [47:10<05:12,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  89%|████████▉ | 748/836 [47:16<06:22,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|████████▉ | 749/836 [47:22<06:43,  4.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|████████▉ | 750/836 [47:24<05:38,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|████████▉ | 751/836 [47:25<04:15,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|████████▉ | 752/836 [47:31<05:36,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|█████████ | 753/836 [47:32<04:21,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|█████████ | 754/836 [47:39<05:33,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|█████████ | 755/836 [47:45<06:19,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  90%|█████████ | 756/836 [47:51<06:43,  5.04s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 757/836 [47:57<07:01,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 758/836 [48:03<07:10,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 759/836 [48:09<07:17,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 760/836 [48:13<06:34,  5.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 761/836 [48:19<06:50,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████ | 762/836 [48:20<05:18,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████▏| 763/836 [48:26<05:52,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  91%|█████████▏| 764/836 [48:32<06:14,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 765/836 [48:39<06:26,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 766/836 [48:45<06:34,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 767/836 [48:48<05:50,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 768/836 [48:55<06:08,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 769/836 [49:01<06:18,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 770/836 [49:06<06:11,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 771/836 [49:08<04:56,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 772/836 [49:15<05:21,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  92%|█████████▏| 773/836 [49:21<05:37,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 774/836 [49:27<05:45,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 775/836 [49:30<04:54,  4.84s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 776/836 [49:31<03:39,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 777/836 [49:34<03:25,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 778/836 [49:37<03:23,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 779/836 [49:43<04:03,  4.27s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 780/836 [49:50<04:29,  4.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  93%|█████████▎| 781/836 [49:56<04:46,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▎| 782/836 [50:02<04:54,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▎| 783/836 [50:08<04:59,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 784/836 [50:14<05:05,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 785/836 [50:20<05:06,  6.01s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 786/836 [50:27<05:05,  6.11s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 787/836 [50:33<05:02,  6.18s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 788/836 [50:39<04:52,  6.09s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 789/836 [50:41<03:46,  4.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  94%|█████████▍| 790/836 [50:47<03:52,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▍| 791/836 [50:53<04:05,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▍| 792/836 [50:56<03:33,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▍| 793/836 [51:03<03:48,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▍| 794/836 [51:09<03:56,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▌| 795/836 [51:16<04:03,  5.94s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▌| 796/836 [51:22<04:05,  6.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▌| 797/836 [51:27<03:38,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  95%|█████████▌| 798/836 [51:32<03:29,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 799/836 [51:34<02:40,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 800/836 [51:40<02:58,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 801/836 [51:46<03:08,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 802/836 [51:49<02:33,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 803/836 [51:55<02:46,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▌| 804/836 [52:01<02:53,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▋| 805/836 [52:08<02:56,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  96%|█████████▋| 806/836 [52:14<02:56,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 807/836 [52:15<02:04,  4.31s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 808/836 [52:18<01:55,  4.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 809/836 [52:25<02:10,  4.85s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 810/836 [52:26<01:37,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 811/836 [52:30<01:37,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 812/836 [52:37<01:53,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 813/836 [52:38<01:20,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 814/836 [52:44<01:36,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  97%|█████████▋| 815/836 [52:51<01:44,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 816/836 [52:52<01:15,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 817/836 [52:52<00:53,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 818/836 [52:54<00:43,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 819/836 [53:00<01:01,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 820/836 [53:01<00:44,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 821/836 [53:01<00:31,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 822/836 [53:08<00:46,  3.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  98%|█████████▊| 823/836 [53:14<00:54,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▊| 824/836 [53:16<00:45,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▊| 825/836 [53:19<00:37,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 826/836 [53:22<00:31,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 827/836 [53:28<00:36,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 828/836 [53:29<00:26,  3.34s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 829/836 [53:36<00:29,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 830/836 [53:42<00:28,  4.75s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct:  99%|█████████▉| 831/836 [53:43<00:19,  3.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct: 100%|█████████▉| 832/836 [53:49<00:18,  4.55s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct: 100%|█████████▉| 833/836 [53:52<00:11,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct: 100%|█████████▉| 834/836 [53:53<00:05,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct: 100%|█████████▉| 835/836 [53:54<00:02,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Generating: Llama-3.1-8B-Instruct: 100%|██████████| 836/836 [53:59<00:00,  3.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('eval_external_llama31_8b/preds/Llama-3.1-8B-Instruct.jsonl')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_chat_template_safe(tok, user_text):\n",
    "    if hasattr(tok, \"apply_chat_template\") and tok.chat_template:\n",
    "        msgs=[{\"role\":\"user\",\"content\":user_text}]\n",
    "        return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    return f\"### Instruction:\\n{user_text}\\n\\n### Response:\\n\"\n",
    "\n",
    "def load_model(model_id):\n",
    "    tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
    "    kwargs = dict(torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "                  device_map=\"auto\")\n",
    "    if USE_4BIT:\n",
    "        kwargs[\"load_in_4bit\"] = True\n",
    "        kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "            load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs).eval()\n",
    "    return tok, model\n",
    "\n",
    "tok, model = load_model(MODEL_ID)\n",
    "\n",
    "preds=[]\n",
    "for ex in tqdm(test_rows, desc=f\"Generating: {MODEL_ID.split('/')[-1]}\"):\n",
    "    instr = ex.get(\"instruction\",\"\")\n",
    "    prompt = apply_chat_template_safe(tok, instr)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**inputs, **GEN_KW, eos_token_id=tok.eos_token_id)\n",
    "    txt = tok.decode(out[0], skip_special_tokens=True)\n",
    "    resp = txt.split(\"### Response:\",1)[-1].strip() if \"### Response:\" in txt else txt.strip()\n",
    "    preds.append({\n",
    "        \"prompt\": instr, \"gold\": ex.get(\"response\",\"\"), \"pred\": resp,\n",
    "        \"target_dialect\": (ex.get(\"dialect\") or ex.get(\"meta\",{}).get(\"dialect\") or \"\").strip()\n",
    "    })\n",
    "\n",
    "out_path = PRED_DIR / f\"{MODEL_ID.split('/')[-1]}.jsonl\"\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for r in preds: f.write(json.dumps(r, ensure_ascii=False)+\"\\n\")\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad80ece",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b7f44-3318-4ef7-a5f9-26839d1ba7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR  = Path(\"eval_external_llama31_8b\")\n",
    "PRED_DIR = OUT_DIR / \"preds\"\n",
    "pred_files = [out_path]  \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------- load 5-way written dialect classifier ----------\n",
    "# Classes: typically {MAGH, LEV, MSA, GLF, EGY}\n",
    "DID_ID   = \"IbrahimAmin/marbertv2-arabic-written-dialect-classifier\"\n",
    "did_tok  = AutoTokenizer.from_pretrained(DID_ID, use_fast=True)\n",
    "did_model= AutoModelForSequenceClassification.from_pretrained(DID_ID).to(device).eval()\n",
    "id2label = did_model.config.id2label\n",
    "label2id = { (v if isinstance(v,str) else v.get(\"name\",\"\")).upper(): int(k) for k,v in id2label.items() }\n",
    "\n",
    "def read_jsonl(p: Path):\n",
    "    rows=[]\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip(): rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def camel_probs_batched(texts, bs=64):\n",
    "    all_probs=[]\n",
    "    for i in tqdm(range(0, len(texts), bs), desc=\"Dialect scoring (MARBERTv2)\", leave=False):\n",
    "        chunk = texts[i:i+bs]\n",
    "        with torch.no_grad():\n",
    "            batch = did_tok(chunk, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "            logits = did_model(**batch).logits\n",
    "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "    return np.vstack(all_probs) if all_probs else np.zeros((0, len(id2label)))\n",
    "\n",
    "def labels_from_probs(probs):\n",
    "    ids = probs.argmax(axis=1)\n",
    "    out=[]\n",
    "    for i in ids:\n",
    "        key = str(i)\n",
    "        lab = id2label[key] if key in id2label else id2label[i]\n",
    "        lab = lab if isinstance(lab, str) else lab.get(\"name\",\"\")\n",
    "        out.append(lab.upper().strip())\n",
    "    return out\n",
    "\n",
    "def is_saudi(lbl: str) -> bool:\n",
    "    # GLF == Gulf Arabic (counts as Saudi-region for this eval)\n",
    "    return \"GLF\" in lbl\n",
    "\n",
    "# MSA class index\n",
    "MSA_IDX = None\n",
    "for raw, idx in label2id.items():\n",
    "    if \"MSA\" in raw:\n",
    "        MSA_IDX = idx\n",
    "        break\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def tag_echo_rate(texts):\n",
    "    patt = re.compile(r'<\\s*DIALECT\\s*=\\s*[^>]+>', re.IGNORECASE)\n",
    "    return 100.0 * float(np.mean([bool(patt.search(t)) for t in texts]))\n",
    "\n",
    "def diversity_metrics(preds):\n",
    "    def ngrams(tokens, n): return list(zip(*[tokens[i:] for i in range(n)]))\n",
    "    total_bi=total_tri=0; uniq_bi=set(); uniq_tri=set()\n",
    "    for p in preds:\n",
    "        t=p.split()\n",
    "        b=ngrams(t,2); g=ngrams(t,3)\n",
    "        total_bi += max(1,len(b)); total_tri += max(1,len(g))\n",
    "        uniq_bi.update(b); uniq_tri.update(g)\n",
    "    d2 = len(uniq_bi)/total_bi if total_bi else 0.0\n",
    "    d3 = len(uniq_tri)/total_tri if total_tri else 0.0\n",
    "    if len(preds) < 2:\n",
    "        sbleu = 0.0\n",
    "    else:\n",
    "        scores=[]\n",
    "        for i in range(len(preds)):\n",
    "            hyp=[preds[i]]\n",
    "            refs=[[p for j,p in enumerate(preds) if j!=i]]\n",
    "            scores.append(sacrebleu.corpus_bleu(hyp, refs).score)\n",
    "        sbleu = float(np.mean(scores))\n",
    "    return d2, d3, sbleu\n",
    "\n",
    "# --- MORE SENSITIVE near-duplicate detector  ---\n",
    "_ar_punct = r\"[^\\w\\s\\u0600-\\u06FF]\"\n",
    "_ar_tatweel = \"\\u0640\"\n",
    "_ar_diacritics = re.compile(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED]\")\n",
    "\n",
    "def normalize_ar(text: str) -> str:\n",
    "    t = text\n",
    "    t = t.replace(_ar_tatweel, \"\")                \n",
    "    t = _ar_diacritics.sub(\"\", t)                 \n",
    "    t = re.sub(r\"\\s+\", \" \", t)                    \n",
    "    t = re.sub(_ar_punct, \" \", t)                  \n",
    "    return t.strip()\n",
    "\n",
    "def near_duplicate_rate(preds, thr=0.90):\n",
    "    if len(preds) < 2:\n",
    "        return 0.0\n",
    "    norm = [normalize_ar(p) for p in preds]\n",
    "    vec = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,3), min_df=1)\n",
    "    X = vec.fit_transform(norm)\n",
    "    sims = cosine_similarity(X)\n",
    "    n = X.shape[0]; cnt = 0; denom = n*(n-1)/2\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if sims[i, j] >= thr:\n",
    "                cnt += 1\n",
    "    return 100.0 * cnt / max(1, denom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca941f",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33407793-cc43-4c9b-a45b-f1e5e333b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-3.1-8B-Instruct label counts: Counter({'GLF': 548, 'LEV': 132, 'MSA': 87, 'EGY': 55, 'MAGHREB': 14})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ar at /workspace/.venv/lib/python3.11/site-packages/bert_score/rescale_baseline/ar/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Summary ==\n",
      "['Llama-3.1-8B-Instruct', 65.55, 11.1, 9.69, 100.0, 17.41, 0.629, 0.6605, 0.7957, 5.11, 0.0]\n",
      "\n",
      "Saved: eval_external_llama31_8b/summary_saudi_only.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- evaluate & summarize ----------\n",
    "summary=[]\n",
    "for pf in pred_files:  \n",
    "    name  = Path(pf).stem\n",
    "    rows  = read_jsonl(pf)\n",
    "    preds = [r[\"pred\"] for r in rows]\n",
    "    golds = [r[\"gold\"] for r in rows]\n",
    "\n",
    "    # dialect predictions\n",
    "    probs = camel_probs_batched(preds, bs=64)\n",
    "    labs  = labels_from_probs(probs)\n",
    "    conf  = probs.max(axis=1)\n",
    "\n",
    "    print(f\"{name} label counts:\", Counter(labs))  \n",
    "\n",
    "    # metrics\n",
    "    msa_leak   = float(np.mean(probs[:, MSA_IDX]))*100.0 if MSA_IDX is not None else 0.0\n",
    "    saudi_rate = 100.0*float(np.mean([is_saudi(x) for x in labs]))\n",
    "    low_conf   = 100.0*float(np.mean(conf < 0.55))\n",
    "    echo       = tag_echo_rate(preds)\n",
    "\n",
    "    chrf = sacrebleu.corpus_chrf(preds, [golds]).score\n",
    "    P,R,F = bertscore(preds, golds, lang=\"ar\", rescale_with_baseline=True)\n",
    "    bert_f1 = float(F.mean().item())\n",
    "\n",
    "    d2, d3, sbleu = diversity_metrics(preds)\n",
    "    near_dup = near_duplicate_rate(preds, thr=0.90)\n",
    "\n",
    "    # per-model JSON\n",
    "    with (OUT_DIR / f\"{name}_report.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"model\": name, \"n\": len(rows),\n",
    "            \"saudi_rate_pct\": saudi_rate,\n",
    "            \"msa_leak_pct\": msa_leak,\n",
    "            \"low_conf_pct\": low_conf,\n",
    "            \"tag_echo_pct\": echo,\n",
    "            \"chrF++\": chrf,\n",
    "            \"BERTScore_F1\": bert_f1,\n",
    "            \"distinct2\": d2, \"distinct3\": d3, \"selfBLEU\": sbleu,\n",
    "            \"near_duplicate_pct\": near_dup\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    summary.append([name, round(saudi_rate,2), round(msa_leak,2), round(low_conf,2),\n",
    "                    round(echo,2), round(chrf,2), round(bert_f1,4),\n",
    "                    round(d2,4), round(d3,4), round(sbleu,2), round(near_dup,2)])\n",
    "\n",
    "# CSV table\n",
    "csv_path = OUT_DIR / \"summary_saudi_only.csv\"\n",
    "with csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"Model\",\"Saudi% (GLF) ↑\",\"MSA leak% ↓\",\"Low-conf% ↓\",\n",
    "                \"Tag-echo% ↓\",\"chrF++ ↑\",\"BERTScore F1 ↑\",\n",
    "                \"distinct-2 ↑\",\"distinct-3 ↑\",\"Self-BLEU ↓\",\"Near-dup% ↓\"])\n",
    "    for row in summary: w.writerow(row)\n",
    "\n",
    "print(\"\\n== Summary ==\")\n",
    "for row in summary: print(row)\n",
    "print(f\"\\nSaved: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allam-eval",
   "language": "python",
   "name": "allam-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
